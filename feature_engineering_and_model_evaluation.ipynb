{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Feature Engineering and Model Evaluation\n",
        "\n",
        "This notebook evaluates the **incremental importance** of newly added features for predicting rotation vs continuation during RTH.\n",
        "\n",
        "## Feature Set\n",
        "\n",
        "**Existing Features:**\n",
        "- `relative_ib_volume`\n",
        "- `normalized_distance`\n",
        "- `opening_bar_open_close`\n",
        "- `norm_opening_bar_volume`\n",
        "- `norm_prev_session_volume`\n",
        "\n",
        "**New Features:**\n",
        "- `nearest_prior_level_to_open` (already exists in phase2 data)\n",
        "- `norm_opening_volatility` (ATR-based)\n",
        "- `news_event_during_RTH` (from events CSV)\n",
        "\n",
        "## Approach\n",
        "- Compare baseline (existing features) vs expanded (existing + new features)\n",
        "- Train Decision Tree, Random Forest, and XGBClassifier\n",
        "- Use stratified 5-fold cross-validation\n",
        "- Account for class imbalance using `class_weight`\n",
        "- Report F1, Precision, Recall\n",
        "- Perform error analysis on misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from datetime import datetime, time, timedelta\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, make_scorer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the phase2 data which contains existing features\n",
        "df = pd.read_csv('outputs/phase2_10min.csv')\n",
        "\n",
        "# Parse session_date\n",
        "df['session_date'] = pd.to_datetime(df['session_date'])\n",
        "\n",
        "print(f\"Loaded {len(df)} sessions\")\n",
        "print(f\"Date range: {df['session_date'].min()} to {df['session_date'].max()}\")\n",
        "print(f\"\\nRotation distribution:\")\n",
        "print(df['rotation'].value_counts())\n",
        "print(f\"\\nClass balance: {df['rotation'].mean():.2%} rotation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {},
      "source": [
        "## Feature Engineering - Task 1: News Event During RTH\n",
        "\n",
        "Create `news_event_during_RTH` from events CSV:\n",
        "- Filter for medium and high impact USD events only\n",
        "- Check if events occur during RTH (6:30am-1:00pm PST)\n",
        "- Binary indicator: 1 if at least one qualifying event, else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load events data\n",
        "events_df = pd.read_csv('Jan01_2025_December31_2025_events.csv')\n",
        "\n",
        "# Parse DateTime column (ISO format with timezone)\n",
        "events_df['DateTime'] = pd.to_datetime(events_df['DateTime'], utc=True)\n",
        "# Convert to PST/America/Los_Angeles timezone\n",
        "events_df['DateTime'] = events_df['DateTime'].dt.tz_convert('America/Los_Angeles')\n",
        "\n",
        "print(f\"Loaded {len(events_df)} events\")\n",
        "print(f\"\\nCurrency distribution:\")\n",
        "print(events_df['Currency'].value_counts().head(10))\n",
        "print(f\"\\nImpact distribution:\")\n",
        "print(events_df['Impact'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter for USD events with medium or high impact\n",
        "usd_events = events_df[\n",
        "    (events_df['Currency'] == 'USD') & \n",
        "    (events_df['Impact'].isin(['Medium Impact Expected', 'High Impact Expected']))\n",
        "].copy()\n",
        "\n",
        "print(f\"USD medium/high impact events: {len(usd_events)}\")\n",
        "\n",
        "# Extract date and time components (already in PST/LA timezone)\n",
        "usd_events['date'] = usd_events['DateTime'].dt.date\n",
        "usd_events['time'] = usd_events['DateTime'].dt.time\n",
        "\n",
        "# Define RTH window (6:30am - 1:00pm PST)\n",
        "RTH_START = time(6, 30)\n",
        "RTH_END = time(13, 0)\n",
        "\n",
        "# Filter events during RTH\n",
        "usd_events_rth = usd_events[\n",
        "    (usd_events['time'] >= RTH_START) & \n",
        "    (usd_events['time'] < RTH_END)\n",
        "]\n",
        "\n",
        "print(f\"USD medium/high impact events during RTH: {len(usd_events_rth)}\")\n",
        "print(f\"\\nSample of RTH events:\")\n",
        "print(usd_events_rth[['DateTime', 'Impact', 'Event']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a set of dates with qualifying news events\n",
        "news_dates = set(usd_events_rth['date'].unique())\n",
        "\n",
        "print(f\"Trading days with news events during RTH: {len(news_dates)}\")\n",
        "\n",
        "# Map to our dataframe\n",
        "df['news_event_during_RTH'] = df['session_date'].dt.date.apply(\n",
        "    lambda d: 1 if d in news_dates else 0\n",
        ")\n",
        "\n",
        "print(f\"\\nNews event distribution in dataset:\")\n",
        "print(df['news_event_during_RTH'].value_counts())\n",
        "print(f\"\\nProportion with news events: {df['news_event_during_RTH'].mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": [
        "## Feature Engineering - Task 2: Normalized Opening Volatility\n",
        "\n",
        "Create `norm_opening_volatility`:\n",
        "- Numerator: 1-minute ATR(14) at 6:45am PST\n",
        "- Denominator: Average RTH ATR(14) over previous 5 trading days\n",
        "- ATR computed on 1-minute bars\n",
        "- No future data leakage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load 1-minute bar data\n",
        "bars_df = pd.read_csv('MNQ_1min_2023Jan_2026Jan.csv')\n",
        "\n",
        "# Parse DateTime\n",
        "bars_df['DateTime'] = pd.to_datetime(bars_df['DateTime'], format='%m/%d/%y %H:%M')\n",
        "\n",
        "# Convert to PST (UTC-8) then to America/Los_Angeles for DST handling\n",
        "from datetime import timezone\n",
        "pst = timezone(timedelta(hours=-8))\n",
        "local_tz = ZoneInfo('America/Los_Angeles')\n",
        "\n",
        "bars_df['DateTime'] = bars_df['DateTime'].apply(\n",
        "    lambda dt: dt.replace(tzinfo=pst).astimezone(local_tz).replace(tzinfo=None)\n",
        ")\n",
        "\n",
        "bars_df['date'] = bars_df['DateTime'].dt.date\n",
        "bars_df['time'] = bars_df['DateTime'].dt.time\n",
        "\n",
        "print(f\"Loaded {len(bars_df)} 1-minute bars\")\n",
        "print(f\"Date range: {bars_df['DateTime'].min()} to {bars_df['DateTime'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to calculate True Range\n",
        "def calculate_tr(df):\n",
        "    \"\"\"Calculate True Range for each bar.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['prev_close'] = df['Close'].shift(1)\n",
        "    \n",
        "    df['tr'] = df.apply(\n",
        "        lambda row: max(\n",
        "            row['High'] - row['Low'],\n",
        "            abs(row['High'] - row['prev_close']) if pd.notna(row['prev_close']) else row['High'] - row['Low'],\n",
        "            abs(row['Low'] - row['prev_close']) if pd.notna(row['prev_close']) else row['High'] - row['Low']\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Function to calculate ATR(14)\n",
        "def calculate_atr(df, period=14):\n",
        "    \"\"\"Calculate ATR using exponential moving average.\"\"\"\n",
        "    df = calculate_tr(df)\n",
        "    df['atr'] = df['tr'].ewm(span=period, adjust=False).mean()\n",
        "    return df\n",
        "\n",
        "# Calculate ATR for all bars\n",
        "bars_df = calculate_atr(bars_df.sort_values('DateTime'))\n",
        "\n",
        "print(\"ATR calculated\")\n",
        "print(f\"Sample ATR values: {bars_df['atr'].describe()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter RTH bars only\n",
        "RTH_START = time(6, 30)\n",
        "RTH_END = time(13, 0)\n",
        "\n",
        "rth_bars = bars_df[\n",
        "    (bars_df['time'] >= RTH_START) & \n",
        "    (bars_df['time'] < RTH_END)\n",
        "].copy()\n",
        "\n",
        "print(f\"RTH bars: {len(rth_bars)}\")\n",
        "\n",
        "# Get unique trading dates (dates with RTH bars)\n",
        "trading_dates = sorted(rth_bars['date'].unique())\n",
        "print(f\"Trading dates with RTH bars: {len(trading_dates)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate norm_opening_volatility for each session\n",
        "def calculate_norm_opening_volatility(target_date, bars_df, trading_dates):\n",
        "    \"\"\"\n",
        "    Calculate normalized opening volatility:\n",
        "    - Numerator: ATR at 6:45am PST on target date\n",
        "    - Denominator: Average RTH ATR over previous 5 trading days\n",
        "    \"\"\"\n",
        "    # Get ATR at 6:45am on target date\n",
        "    target_645am = bars_df[\n",
        "        (bars_df['date'] == target_date) & \n",
        "        (bars_df['time'] == time(6, 45))\n",
        "    ]\n",
        "    \n",
        "    if len(target_645am) == 0:\n",
        "        return None\n",
        "    \n",
        "    opening_atr = target_645am.iloc[0]['atr']\n",
        "    \n",
        "    if pd.isna(opening_atr):\n",
        "        return None\n",
        "    \n",
        "    # Find previous 5 trading dates\n",
        "    try:\n",
        "        target_idx = trading_dates.index(target_date)\n",
        "    except ValueError:\n",
        "        return None\n",
        "    \n",
        "    if target_idx < 5:\n",
        "        return None  # Not enough history\n",
        "    \n",
        "    prev_5_dates = trading_dates[target_idx-5:target_idx]\n",
        "    \n",
        "    # Calculate average RTH ATR over previous 5 days\n",
        "    prev_rth_bars = bars_df[\n",
        "        (bars_df['date'].isin(prev_5_dates)) &\n",
        "        (bars_df['time'] >= RTH_START) &\n",
        "        (bars_df['time'] < RTH_END)\n",
        "    ]\n",
        "    \n",
        "    if len(prev_rth_bars) == 0:\n",
        "        return None\n",
        "    \n",
        "    avg_rth_atr = prev_rth_bars['atr'].mean()\n",
        "    \n",
        "    if pd.isna(avg_rth_atr) or avg_rth_atr == 0:\n",
        "        return None\n",
        "    \n",
        "    return opening_atr / avg_rth_atr\n",
        "\n",
        "# Apply to each session\n",
        "df['norm_opening_volatility'] = df['session_date'].dt.date.apply(\n",
        "    lambda d: calculate_norm_opening_volatility(d, bars_df, trading_dates)\n",
        ")\n",
        "\n",
        "print(f\"\\nNormalized opening volatility statistics:\")\n",
        "print(df['norm_opening_volatility'].describe())\n",
        "print(f\"\\nMissing values: {df['norm_opening_volatility'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## Prepare Features for Modeling\n",
        "\n",
        "Calculate missing features:\n",
        "- `normalized_distance`: nearest_prior_level_distance / prev_range\n",
        "- Normalized volume features using rolling averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate normalized_distance feature\n",
        "# normalized_distance = nearest_prior_level_distance / previous day range\n",
        "df['prev_range'] = df['prev_pdh'] - df['prev_pdl']\n",
        "df['prev_range'] = df['prev_range'].replace(0, np.nan)  # Avoid div-by-zero\n",
        "df['normalized_distance'] = df['nearest_prior_level_to_open_distance'] / df['prev_range']\n",
        "df['normalized_distance'] = df['normalized_distance'].fillna(0)\n",
        "\n",
        "print(f\"Calculated normalized_distance\")\n",
        "print(f\"Stats: {df['normalized_distance'].describe()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate normalized volume features\n",
        "# Use rolling average for normalization (consistent with mp3_analysis_variables.py)\n",
        "\n",
        "# Sort by date for rolling calculations\n",
        "df = df.sort_values('session_date').reset_index(drop=True)\n",
        "\n",
        "# Calculate 10-day rolling average for normalization\n",
        "window = 10\n",
        "df['avg_opening_bar_volume'] = df['opening_bar_volume'].rolling(\n",
        "    window=window, min_periods=1\n",
        ").mean().shift(1)  # Shift to avoid future leakage\n",
        "\n",
        "df['avg_prev_session_volume'] = df['prev_session_volume'].rolling(\n",
        "    window=window, min_periods=1\n",
        ").mean().shift(1)\n",
        "\n",
        "# Normalize\n",
        "df['norm_opening_bar_volume'] = df['opening_bar_volume'] / df['avg_opening_bar_volume']\n",
        "df['norm_prev_session_volume'] = df['prev_session_volume'] / df['avg_prev_session_volume']\n",
        "\n",
        "# Handle infinity and NaN\n",
        "df['norm_opening_bar_volume'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df['norm_prev_session_volume'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "print(\"Normalized volume features calculated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define feature sets\n",
        "existing_features = [\n",
        "    'relative_ib_volume',\n",
        "    'normalized_distance',\n",
        "    'opening_bar_open_close',\n",
        "    'norm_opening_bar_volume',\n",
        "    'norm_prev_session_volume'\n",
        "]\n",
        "\n",
        "new_features = [\n",
        "    'nearest_prior_level_to_open_distance',  # Already in phase2 data\n",
        "    'norm_opening_volatility',\n",
        "    'news_event_during_RTH'\n",
        "]\n",
        "\n",
        "all_features = existing_features + new_features\n",
        "\n",
        "# Prepare target\n",
        "y = df['rotation'].astype(int)\n",
        "\n",
        "# Prepare feature matrices\n",
        "X_baseline = df[existing_features].copy()\n",
        "X_expanded = df[all_features].copy()\n",
        "\n",
        "# Drop rows with missing values\n",
        "valid_baseline = ~X_baseline.isna().any(axis=1)\n",
        "valid_expanded = ~X_expanded.isna().any(axis=1)\n",
        "\n",
        "# For fair comparison, use only rows that have valid data for all features\n",
        "valid_rows = valid_baseline & valid_expanded\n",
        "\n",
        "X_baseline_clean = X_baseline[valid_rows]\n",
        "X_expanded_clean = X_expanded[valid_rows]\n",
        "y_clean = y[valid_rows]\n",
        "\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Original: {len(df)}\")\n",
        "print(f\"After cleaning: {len(X_baseline_clean)}\")\n",
        "print(f\"Dropped: {len(df) - len(X_baseline_clean)}\")\n",
        "print(f\"\\nClass distribution (cleaned):\")\n",
        "print(y_clean.value_counts())\n",
        "print(f\"Rotation rate: {y_clean.mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation\n",
        "\n",
        "Train and compare:\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- XGBClassifier\n",
        "\n",
        "For both baseline and expanded feature sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models with class_weight for imbalance\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        max_depth=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'XGBClassifier': XGBClassifier(\n",
        "        max_depth=5,\n",
        "        n_estimators=100,\n",
        "        scale_pos_weight=(y_clean == 0).sum() / (y_clean == 1).sum(),\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "}\n",
        "\n",
        "# Define cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score)\n",
        "}\n",
        "\n",
        "print(\"Models and CV strategy defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate baseline models\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE MODELS (Existing Features Only)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Features: {existing_features}\\n\")\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    \n",
        "    cv_results = cross_validate(\n",
        "        model, X_baseline_clean, y_clean,\n",
        "        cv=cv, scoring=scoring, return_train_score=False\n",
        "    )\n",
        "    \n",
        "    baseline_results[model_name] = {\n",
        "        'f1_mean': cv_results['test_f1'].mean(),\n",
        "        'f1_std': cv_results['test_f1'].std(),\n",
        "        'precision_mean': cv_results['test_precision'].mean(),\n",
        "        'precision_std': cv_results['test_precision'].std(),\n",
        "        'recall_mean': cv_results['test_recall'].mean(),\n",
        "        'recall_std': cv_results['test_recall'].std(),\n",
        "    }\n",
        "    \n",
        "    print(f\"  F1 Score:   {baseline_results[model_name]['f1_mean']:.4f} \u00b1 {baseline_results[model_name]['f1_std']:.4f}\")\n",
        "    print(f\"  Precision:  {baseline_results[model_name]['precision_mean']:.4f} \u00b1 {baseline_results[model_name]['precision_std']:.4f}\")\n",
        "    print(f\"  Recall:     {baseline_results[model_name]['recall_mean']:.4f} \u00b1 {baseline_results[model_name]['recall_std']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate expanded models\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPANDED MODELS (Existing + New Features)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Features: {all_features}\\n\")\n",
        "\n",
        "expanded_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    \n",
        "    cv_results = cross_validate(\n",
        "        model, X_expanded_clean, y_clean,\n",
        "        cv=cv, scoring=scoring, return_train_score=False\n",
        "    )\n",
        "    \n",
        "    expanded_results[model_name] = {\n",
        "        'f1_mean': cv_results['test_f1'].mean(),\n",
        "        'f1_std': cv_results['test_f1'].std(),\n",
        "        'precision_mean': cv_results['test_precision'].mean(),\n",
        "        'precision_std': cv_results['test_precision'].std(),\n",
        "        'recall_mean': cv_results['test_recall'].mean(),\n",
        "        'recall_std': cv_results['test_recall'].std(),\n",
        "    }\n",
        "    \n",
        "    print(f\"  F1 Score:   {expanded_results[model_name]['f1_mean']:.4f} \u00b1 {expanded_results[model_name]['f1_std']:.4f}\")\n",
        "    print(f\"  Precision:  {expanded_results[model_name]['precision_mean']:.4f} \u00b1 {expanded_results[model_name]['precision_std']:.4f}\")\n",
        "    print(f\"  Recall:     {expanded_results[model_name]['recall_mean']:.4f} \u00b1 {expanded_results[model_name]['recall_std']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "## Results Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "import pandas as pd\n",
        "\n",
        "comparison_data = []\n",
        "\n",
        "for model_name in models.keys():\n",
        "    baseline = baseline_results[model_name]\n",
        "    expanded = expanded_results[model_name]\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Model': model_name,\n",
        "        'Feature Set': 'Baseline',\n",
        "        'F1 Score': f\"{baseline['f1_mean']:.4f} \u00b1 {baseline['f1_std']:.4f}\",\n",
        "        'Precision': f\"{baseline['precision_mean']:.4f} \u00b1 {baseline['precision_std']:.4f}\",\n",
        "        'Recall': f\"{baseline['recall_mean']:.4f} \u00b1 {baseline['recall_std']:.4f}\"\n",
        "    })\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Model': model_name,\n",
        "        'Feature Set': 'Expanded',\n",
        "        'F1 Score': f\"{expanded['f1_mean']:.4f} \u00b1 {expanded['f1_std']:.4f}\",\n",
        "        'Precision': f\"{expanded['precision_mean']:.4f} \u00b1 {expanded['precision_std']:.4f}\",\n",
        "        'Recall': f\"{expanded['recall_mean']:.4f} \u00b1 {expanded['recall_std']:.4f}\"\n",
        "    })\n",
        "    \n",
        "    # Calculate improvement\n",
        "    f1_improvement = expanded['f1_mean'] - baseline['f1_mean']\n",
        "    precision_improvement = expanded['precision_mean'] - baseline['precision_mean']\n",
        "    recall_improvement = expanded['recall_mean'] - baseline['recall_mean']\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Model': model_name,\n",
        "        'Feature Set': '\u0394 (Improvement)',\n",
        "        'F1 Score': f\"{f1_improvement:+.4f}\",\n",
        "        'Precision': f\"{precision_improvement:+.4f}\",\n",
        "        'Recall': f\"{recall_improvement:+.4f}\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Error Analysis\n",
        "\n",
        "Identify misclassified samples to understand systematic failure modes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final models on full data for error analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data for error analysis\n",
        "X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
        "    X_baseline_clean, y_clean, test_size=0.3, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "X_train_exp, X_test_exp, _, _ = train_test_split(\n",
        "    X_expanded_clean, y_clean, test_size=0.3, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train_base)} samples\")\n",
        "print(f\"Test set: {len(X_test_base)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to perform error analysis\n",
        "def error_analysis(model, X_train, X_test, y_train, y_test, model_name, feature_names):\n",
        "    \"\"\"\n",
        "    Train model and analyze misclassified samples.\n",
        "    \"\"\"\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    # Find misclassified samples\n",
        "    misclassified = y_test != y_pred\n",
        "    misclassified_indices = X_test[misclassified].index\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{model_name} - Error Analysis\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total test samples: {len(y_test)}\")\n",
        "    print(f\"Misclassified: {misclassified.sum()} ({misclassified.mean()*100:.2f}%)\")\n",
        "    print(f\"\\nBreakdown of errors:\")\n",
        "    \n",
        "    # False positives and false negatives\n",
        "    false_positives = ((y_test == 0) & (y_pred == 1)).sum()\n",
        "    false_negatives = ((y_test == 1) & (y_pred == 0)).sum()\n",
        "    \n",
        "    print(f\"  False Positives (predicted rotation, was not): {false_positives}\")\n",
        "    print(f\"  False Negatives (predicted no rotation, was rotation): {false_negatives}\")\n",
        "    \n",
        "    # Show first 10 misclassified samples\n",
        "    print(f\"\\nFirst 10 misclassified samples:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    for i, idx in enumerate(misclassified_indices[:10]):\n",
        "        true_label = \"Rotation\" if y_test.loc[idx] == 1 else \"No Rotation\"\n",
        "        pred_label = \"Rotation\" if y_pred[y_test.index.get_loc(idx)] == 1 else \"No Rotation\"\n",
        "        \n",
        "        print(f\"\\nSample {i+1} (Index: {idx}):\")\n",
        "        print(f\"  True Label: {true_label}\")\n",
        "        print(f\"  Predicted:  {pred_label}\")\n",
        "        print(f\"  Features:\")\n",
        "        \n",
        "        for feat_name in feature_names:\n",
        "            feat_value = X_test.loc[idx, feat_name]\n",
        "            print(f\"    {feat_name}: {feat_value:.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    \n",
        "    return model, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform error analysis for each model - Baseline\n",
        "print(\"\\n\" + \"#\"*80)\n",
        "print(\"ERROR ANALYSIS - BASELINE MODELS\")\n",
        "print(\"#\"*80)\n",
        "\n",
        "baseline_trained = {}\n",
        "for model_name, model in models.items():\n",
        "    trained_model, predictions = error_analysis(\n",
        "        model, X_train_base, X_test_base, y_train, y_test,\n",
        "        f\"{model_name} (Baseline)\", existing_features\n",
        "    )\n",
        "    baseline_trained[model_name] = trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform error analysis for each model - Expanded\n",
        "print(\"\\n\" + \"#\"*80)\n",
        "print(\"ERROR ANALYSIS - EXPANDED MODELS\")\n",
        "print(\"#\"*80)\n",
        "\n",
        "expanded_trained = {}\n",
        "for model_name, model in models.items():\n",
        "    trained_model, predictions = error_analysis(\n",
        "        model, X_train_exp, X_test_exp, y_train, y_test,\n",
        "        f\"{model_name} (Expanded)\", all_features\n",
        "    )\n",
        "    expanded_trained[model_name] = trained_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-28",
      "metadata": {},
      "source": [
        "## Summary and Conclusions\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **New Features Added:**\n",
        "   - `news_event_during_RTH`: Binary indicator for medium/high impact USD news during RTH\n",
        "   - `norm_opening_volatility`: Ratio of opening ATR to recent average ATR\n",
        "   - `nearest_prior_level_to_open_distance`: Already present in phase2 data\n",
        "\n",
        "2. **Model Comparison:**\n",
        "   - Three classifiers evaluated: Decision Tree, Random Forest, XGBClassifier\n",
        "   - Both baseline and expanded feature sets tested\n",
        "   - 5-fold stratified cross-validation used\n",
        "   - Class imbalance handled via `class_weight`\n",
        "\n",
        "3. **Performance Metrics:**\n",
        "   - F1 Score, Precision, and Recall reported for each model\n",
        "   - Incremental improvements from new features quantified\n",
        "\n",
        "4. **Error Analysis:**\n",
        "   - Misclassified samples identified and analyzed\n",
        "   - Feature vectors printed for systematic failure investigation\n",
        "\n",
        "### Assumptions\n",
        "- **Timezone:** All times in PST/America/Los_Angeles (handles DST)\n",
        "- **RTH Window:** 6:30am - 1:00pm PST\n",
        "- **Trading days:** Only dates with RTH bars included\n",
        "- **Holiday calendar:** Implicitly handled via available bar data\n",
        "- **Missing data:** Rows with any missing features dropped\n",
        "- **No future leakage:** Rolling averages use only past data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}